# SAP 오답노트 2주차

- SAP 시험을 준비하며 틀린 문제나 부족한 부분을 정리한다.

---

#### 문제

- 여러 AWS 계정을 보유한 회사가 AWS Organizations 및 서비스 제어 정책(SCP)을 사용하고 있습니다. 관리자가 다음 SCP를 생성하여 AWS 계정 1111-1111-1111이 포함된 조직 단위(OU)에 연결했습니다.

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "AllowsAllActions",
      "Effect": "Allow",
      "Action": "*",
      "Resource": "*"
    },
    {
      "Sid": "DenyCloudTrail",
      "Effect": "Deny",
      "Action": "cloudtrail:*",
      "Resource": "*"
    }
  ]
}
```

- 계정 1111-1111-1111에서 작업하는 개발자는 Amazon S3 버킷을 생성할 수 없다고 불평합니다. 관리자는 이 문제를 어떻게 해결해야 합니까?

#### 보기

- A: "허용" 효과가 있는 s3:CreateBucket을 SCP에 추가합니다.
- B: OU에서 계정을 제거하고 SCP를 계정 1111-1111-1111에 직접 연결합니다.
- C: 개발자에게 IAM 엔터티에 Amazon S3 권한을 추가하도록 지시합니다.
- D: 계정 1111-1111-1111에서 SCP를 제거합니다.

#### 정답

- 정답: C
- SCP만으로는 조직의 계정에 권한을 부여하는데 충분하지 않다. SCP는 권한을 부여하지 않는다. SCP는 계정 관리자가 영향을 받는 계정의 IAM 사용자 및 역할에 위임할 수 있는 작업에 대한 가드레일을 정의하거나 제한을 설정한다.
- 실제로 권한을 부여하려면 관리자가 자격 증명 기반 또는 리소스 기반 정책을 IAM 사용자나 역할 또는 계정의 리소스에 연결해야 한다. 유효한 권한은 SCP에서 허용하는 것과 IAM 및 리소스 기반 정책에서 허용하는 것 간의 논리적 교차점이다.
- C에서 올바른 SCP 정책으로 CloudTrail을 제외한 모든 것을 허용한다. SCP는 경계이지만 IAM 사용자에게는 허용되지 않으므로 모든 IAM에 대한 허용을 구성해야 한다.

---

#### 문제

- 회사에는 회사 비즈니스에 중요한 모놀리식 애플리케이션이 있습니다. 회사는 Amazon Linux 2를 실행하는 Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다. 
- 회사의 애플리케이션 팀은 법무 부서로부터 인스턴스의 암호화된 Amazon Elastic Block Store(Amazon EBS) 볼륨의 데이터를 Amazon S3 버킷에 백업하라는 지시를 받습니다.
- 애플리케이션 팀에는 인스턴스에 대한 관리 SSH 키 쌍이 없습니다. 애플리케이션은 계속해서 사용자에게 서비스를 제공해야 합니다.
- 어떤 솔루션이 이러한 요구 사항을 충족합니까?

#### 보기

- A: Amazon S3에 쓸 수 있는 권한이 있는 인스턴스에 역할을 연결합니다. AWS 시스템 관리자 세션 관리자 옵션을 사용하여 인스턴스에 액세스하고 명령을 실행하여 Amazon S3에 데이터를 복사합니다.
- B: 재부팅 옵션이 활성화된 인스턴스의 이미지를 생성합니다. 이미지에서 새 EC2 인스턴스를 시작합니다. Amazon S3에 쓰기 권한이 있는 새 인스턴스에 역할을 연결합니다. Amazon S3에 데이터를 복사하는 명령을 실행합니다.
- C: Amazon Data Lifecycle Manager(Amazon DLM)를 사용하여 EBS 볼륨의 스냅샷을 만듭니다. 데이터를 Amazon S3에 복사합니다.
- D: 인스턴스의 이미지를 생성합니다. 이미지에서 새 EC2 인스턴스를 시작합니다. Amazon S3에 쓰기 권한이 있는 새 인스턴스에 역할을 연결합니다. Amazon S3에 데이터를 복사하는 명령을 실행합니다.

#### 정답

- 정답: A 또는 C
- A는 조금 복잡한 작업이 필요하지만 실현 가능한 방법이다.
- C가 정답이라는 의견이 많이 있으나 문제에서는 S3로 백업을 하는 것이지 스냅샷을 백업하라는 표현을 사용하고 있지는 않다. 만약 스냅샷을 백업하는 것이 문제의 요구사항을 충족시키지 못한다면 정답은 A가 된다.
- 또한 Data Lifecycle Manager(DLM)는 EBS 볼륨의 자동화된 스냅샷 관리를 위한 서비스이지만, 직접적으로 S3에 데이터를 백업하는 기능은 제공하지 않는다.

---

#### 문제

- 솔루션 아키텍트는 AWS 계정의 Amazon S3 버킷에서 새 AWS 계정의 새 S3 버킷으로 데이터를 복사해야 합니다. 솔루션 아키텍트는 AWS CLI를 사용하는 솔루션을 구현해야 합니다.
- 데이터를 성공적으로 복사하려면 어떤 단계를 조합해야 합니까? (3개를 선택하세요.)

#### 보기

- A: 원본 버킷이 해당 콘텐츠를 나열하고 대상 버킷에 객체를 배치하고 객체 ACL을 설정할 수 있도록 버킷 정책을 생성합니다. 버킷 정책을 대상 버킷에 연결합니다.
- B: 대상 계정의 사용자가 원본 버킷의 콘텐츠를 나열하고 원본 버킷의 객체를 읽을 수 있도록 허용하는 버킷 정책을 만듭니다. 버킷 정책을 원본 버킷에 연결합니다.
- C: 원본 계정에서 IAM 정책을 생성합니다. 원본 계정의 사용자가 원본 버킷에서 콘텐츠를 나열하고 객체를 가져올 수 있도록 허용하고, 대상 버킷에서 콘텐츠를 나열하고 객체를 넣고 객체 ACL을 설정할 수 있도록 정책을 구성합니다. 정책을 사용자에게 연결합니다.
- D: 대상 계정에 IAM 정책을 생성합니다. 대상 계정의 사용자가 원본 버킷에서 콘텐츠를 나열하고 객체를 가져올 수 있도록 허용하고, 대상 버킷에서 콘텐츠를 나열하고 객체를 넣고 objectACL을 설정할 수 있도록 정책을 구성합니다. 정책을 사용자에게 연결합니다.
- E: 원본 계정의 사용자로 aws s3 sync 명령을 실행합니다. 데이터를 복사할 소스 및 대상 버킷을 지정합니다.
- F: 대상 계정의 사용자로 aws s3 sync 명령을 실행합니다. 데이터를 복사할 소스 및 대상 버킷을 지정합니다.

#### 정답

- 정답: B, D, F
- 대상 계정의 사용자가 원본 버킷에 액세스하고 해당 콘텐츠를 나열하고 객체를 읽는데 필요한 권한을 가지려면 B 옵션이 필요하다.
- 대상 계정의 사용자가 버킷에 액세스하고 콘텐츠를 나열하고, 객체를 넣고, 객체 ACL을 설정하는데 필요한 권한을 가지려면 D 옵션이 필요하다.
- `aws s3 sync` 명령은 대상 계정에서 실행해야 한다. 그렇지 않으면 대상 S3 버킷에 복사된 객체는 여전히 원본 계정의 권한을 가지며 대상 계정 사용자가 액세스할 수 없다.
  - 객체가 한 버킷에서 다른 버킷으로 복사될 때 객체의 권한(ACL)도 복사되기 때문이다.
  - 따라서 원본 계정의 IAM 사용자 자격 증명을 사용하여 객체를 복사하면 객체는 원본 버킷에서와 동일한 권한을 갖게 되지만 대상 계정의 사용자에 대한 권한은 포함되지 않을 수 있다.
  - 대상 계정의 IAM 사용자 자격 증명을 사용하면 객체가 복사된 후 대상 계정의 사용자에 대한 적절한 권한을 갖게 된다.

---

#### 문제

- 한 회사는 AWS CloudFormation 스택에 배포된 AWS Lambda를 기반으로 애플리케이션을 구축했습니다. 웹 애플리케이션의 마지막 프로덕션 릴리스에서는 몇 분 동안 중단이 발생하는 문제가 발생했습니다. 
- 솔루션 설계자는 Canary 릴리스를 지원하도록 배포 프로세스를 조정해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?

#### 보기

- A: 새로 배포된 모든 버전의 Lambda 함수에 대한 별칭을 생성합니다. AWS CLI update-alias 명령을 Routing-config 파라미터와 함께 사용하여 로드를 분산하십시오.
- B: 애플리케이션을 새로운 CloudFormation 스택에 배포합니다. 부하를 분산하려면 Amazon Route 53 가중치 기반 라우팅 정책을 사용하십시오.
- C: 새로 배포된 모든 Lambda 함수에 대한 버전을 생성합니다. AWS CLI update-function-configuration 명령을 Routing-config 파라미터와 함께 사용하여 로드를 분산하십시오.
- D: AWS CodeDeploy를 구성하고 배포 구성에서 CodeDeployDefault.OneAtATime을 사용하여 로드를 분산시킵니다.

#### 정답

- 정답: A
- 새롭게 배포된 모든 버전의 람다 함수에 대한 별칭을 생성한다. AWS CLI `update-alias` 명령을 사용하여 `Routing-config` 파라미터를 설정하여 트래픽을 분산한다.
- C는 카나리 릴리즈를 허용하지만 새로 배포된 모든 람다 함수에 대한 버전을 생성해야 하기 때문에 올바르지 않다. 이는 새 버전의 람두에 대한 별칭을 생성하는 것에 비해 더 복잡하고 많은 시간을 요구한다.

---

#### 문제

- 금융 회사는 Amazon S3에서 데이터 레이크를 호스팅합니다. 회사는 매일 밤 여러 제3자로부터 SFTP를 통해 금융 데이터 기록을 받습니다. 이 회사는 VPC의 퍼블릭 서브넷에 있는 Amazon EC2 인스턴스에서 자체 SFTP 서버를 실행합니다. 
- 파일이 업로드된 후 동일한 인스턴스에서 실행되는 크론 작업을 통해 데이터 레이크로 이동됩니다. SFTP 서버는 Amazon Route 53을 사용하여 DNS sftp.example.com에 연결할 수 있습니다.
- SFTP 솔루션의 안정성과 확장성을 개선하려면 솔루션 설계자가 무엇을 해야 합니까?

#### 보기

- A: EC2 인스턴스를 Auto Scaling 그룹으로 이동합니다. Application Load Balancer(ALB) 뒤에 EC2 인스턴스를 배치합니다. ALB를 가리키도록 Route 53의 DNS 레코드 sftp.example.com을 업데이트합니다.
- B: SFTP 서버를 SFTP용 AWS 전송으로 마이그레이션합니다. 서버 엔드포인트 호스트 이름을 가리키도록 Route 53의 DNS 레코드 sftp.example.com을 업데이트합니다.
- C: SFTP 서버를 AWS Storage Gateway의 파일 게이트웨이로 마이그레이션합니다. 파일 게이트웨이 엔드포인트를 가리키도록 Route 53의 DNS 레코드 sftp.example.com을 업데이트합니다.
- D: NLB(Network Load Balancer) 뒤에 EC2 인스턴스를 배치합니다. NLB를 가리키도록 Route 53의 DNS 레코드 sftp.example.com을 업데이트합니다.

#### 정답

- 정답: B
- A에서 Auto Scaling 그룹은 트래픽 증가에 대비하여 인스턴스를 자동으로 확장할 수 있지만 단일 장애 지점을 해결하지 못하며, ALB는 SFTP와 호환되지 않는다.
- B에서 SFTP 서버를 AWS Transfer for SFTP로 마이그레이션하면 SFTP 솔루션의 안정성과 확장성이 향상된다. 
  - AWS Transfer for SFTP는 SFTP 프로토콜을 사용하여 S3 안팎으로 파일을 직접 전송할 수 있게 해주는 완전관리형 SFTP 서비스다.
  - 이 서비스를 사용하면 회사는 SFTP 서버 관리를 AWS로 오프로드할 수 있어 고가용성, 확장성 및 보안이 제공된다.
  - 그런 다음 회사는 Route 53의 DNS 레코드를 sftp.example.com을 업데이트하여 서버 엔드포인트 호스트 이름을 가리키도록 할 수 있다.

---

#### 문제

- 회사는 온프레미스 데이터 센터에서 실행되는 VMware 인프라에서 Amazon EC2로 애플리케이션을 마이그레이션하려고 합니다. 솔루션 설계자는 마이그레이션 중에 소프트웨어 및 구성 설정을 보존해야 합니다.
- 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

#### 보기

- A: 데이터 저장소를 Amazon FSx for Windows File Server로 복제하기 시작하도록 AWS DataSync 에이전트를 구성합니다. SMB 공유를 사용하여 VMware 데이터 저장소를 호스팅합니다. VM Import/Export를 사용하여 VM을 Amazon EC2로 이동합니다.
- B: VMware vSphere 클라이언트를 사용하여 애플리케이션을 OVF(Open Virtualization Format) 형식의 이미지로 내보냅니다. 대상 AWS 리전에 이미지를 저장할 Amazon S3 버킷을 생성합니다. VM Import를 위한 IAM 역할을 생성하고 적용합니다. AWS CLI를 사용하여 EC2 가져오기 명령을 실행합니다.
- C: CIFS(Common Internet File System) 공유를 내보내도록 파일 서비스용 AWS Storage Gateway를 구성합니다. 공유 폴더에 백업 복사본을 만듭니다. AWS Management Console에 로그인하고 백업 복사본에서 AMI를 생성합니다. AMI를 기반으로 하는 EC2 인스턴스를 시작합니다.
- D: AWS 시스템 관리자에서 하이브리드 환경을 위한 관리형 인스턴스 활성화를 생성합니다. 온프레미스 VM에 Systems Manager 에이전트를 다운로드하고 설치합니다. VM을 Systems Manager에 등록하여 관리형 인스턴스로 만듭니다. AWS Backup을 사용하여 VM의 스냅샷을 생성하고 AMI를 생성합니다. AMI를 기반으로 하는 EC2 인스턴스를 시작합니다.

#### 정답

- 정답: B
- VMware vSphere 클라이언트를 사용하여 OVF 형식으로 이미지를 내보내는 것은 소프트웨어 및 구성 설정을 포함한 전체 VM을 복제하는 가장 간단하고 효과적인 방법이다.
  - VMware vSphere 클라이언트를 사용하여 애플리케이션을 OVF(Open Virtualization Format) 형식의 이미지로 내보낸다. 
  - 대상 AWS 리전에 이미지를 저장할 S3 버킷을 생성한다.
  - VM Import를 위한 IAM 역할을 생성하고 적용한다.
  - AWS CLI를 사용하여 EC2 가져오기 명령을 실행한다.
  - 이 접근 방식을 사용하면 솔루션 설계자가 소프트웨어 및 구성 설정을 유지하는 OVF 형식의 이미지로 애플리케이션을 내보낸 다음 EC2 가져오기 명령을 사용하여 EC2로 가져올 수 있다.
- D의 경우 하이브리드 환경을 위한 관리형 인스턴스 활성화를 생성하고 관리형 인스턴스로 VM을 등록한 후 AWS Backup을 사용하여 스냅샷을 생성하고 AMI를 만들어 EC2 인스턴스를 시작하는 것을 제안한다.
  - 하지만 이러한 방법은 VMware 인프라에서 실행 중인 애플리케이션을 마이그레이션하는 데에는 적합하지 않다.
  - 이 방법은 온프레미스 환경에서 이미 실행 중인 VM을 백업하여 EC2 인스턴스로 마이그레이션하는 것이 아니라, 관리형 인스턴스로 변환하고 해당 인스턴스를 백업하여 EC2 인스턴스로 시작하는 것이다.

---

#### 문제

- 회사는 AWS Organizations에 조직을 가지고 있습니다. 회사는 AWS Control Tower를 사용하여 조직의 랜딩 존을 배포하고 있습니다. 회사는 거버넌스 및 정책 시행을 구현하기를 원합니다. 
- 회사는 회사의 프로덕션 OU에 저장되어 있는 암호화되지 않은 Amazon RDS DB 인스턴스를 감지하는 정책을 구현해야 합니다.
- 이 요구 사항을 충족하는 솔루션은 무엇입니까?

#### 보기

- A: AWS Control Tower에서 필수 가드레일을 활성화합니다. 프로덕션 OU에 필수 가드레일을 적용합니다.
- B: AWS Control Tower의 강력 권장 가드레일 목록에서 적절한 가드레일을 활성화합니다. 프로덕션 OU에 가드레일을 적용합니다.
- C: AWS Config를 사용하여 새로운 필수 가드레일을 생성합니다. 프로덕션 OU의 모든 계정에 규칙을 적용합니다.
- D: AWS Control Tower에서 사용자 지정 SCP를 생성합니다. 프로덕션 OU에 SCP를 적용합니다.

#### 정답

- 정답: B
- AWS Control Tower의 강력 권장 가드레일에는 암호화되지 않은 RDS DB 인스턴스를 감지하는 기능이 포함되어 있다.
  - 이는 D에서 제안한 사용자 지정 SCP를 만드는 것보다 더 간단하고 빠른 솔루션이다.
- 강력 권장 가드레일은 AWS에서 관리 및 유지 관리된다.
  - 이는 사용자 지정 SCP를 관리하는 것보다 더 간편하고 안전하다.
- 강력 권장 가드레일은 프로덕션 OU에 쉽게 적용할 수 있다.
  - 이렇게 하면 OU 내의 모든 계정이 암호화되지 않은 RDS DB 인스턴스를 사용하지 않도록 보장할 수 있다.
- A: 필수 가드레일은 기본적인 보안 및 준수 요구 사항을 충족하도록 설계되었다. 암호화되지 않은 RDS DB 인스턴스를 감지하는 기능은 필수 가드레일에 포함되지 않는다.
- C: AWS Config를 사용하여 사용자 지정 규칙을 만들 수 있지만 이 규칙을 프로덕션 OU의 모든 계정에 적용하는 것은 어려울 수 있다. 또한, AWS Config는 SCP만큼 강력하지 않다.
- D: 사용자 지정 SCP는 특정 요구 사항에 맞게 조정할 수 있는 맞춤형 정책이다. 그러나 이번 문제에서는 강력 권장 가드레일을 사용하는 것이 더 간단하고 빠른 솔루션이다.

---

#### 문제

- AWS Organizations를 사용하는 회사에서는 개발자가 AWS를 실험할 수 있습니다. 회사가 배포한 랜딩 존의 일부로 개발자는 회사 이메일 주소를 사용하여 계정을 요청합니다. 
- 회사는 개발자가 비용이 많이 드는 서비스를 출시하거나 불필요하게 서비스를 실행하지 않도록 하고 싶어합니다. 회사는 AWS 비용을 제한하기 위해 개발자에게 고정된 월별 예산을 제공해야 합니다.
- 이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (3개를 선택하세요.)

#### 보기

- A: 고정된 월간 계정 사용 제한을 설정하려면 SCP를 생성하십시오. 개발자 계정에 SCP를 적용합니다.
- B: AWS 예산을 사용하여 계정 생성 프로세스의 일부로 각 개발자 계정에 대한 고정 월 예산을 생성합니다.
- C: 비용이 많이 드는 서비스 및 구성 요소에 대한 액세스를 거부하는 SCP를 만듭니다. 개발자 계정에 SCP를 적용합니다.
- D: 비용이 많이 드는 서비스 및 구성 요소에 대한 액세스를 거부하는 IAM 정책을 만듭니다. 개발자 계정에 IAM 정책을 적용합니다.
- E: 예산 금액에 도달하면 서비스를 종료하는 AWS 예산 알림 작업을 생성합니다. 모든 서비스를 종료하는 작업을 구성합니다.
- F: 예산 금액에 도달하면 Amazon Simple 알림 서비스(Amazon SNS) 알림을 보내는 AWS 예산 알림 작업을 생성합니다. AWS Lambda 함수를 호출하여 모든 서비스를 종료합니다.

#### 정답

- 정답: B, D, F
- B: AWS 예산을 사용하여 각 개발자 계정에 대한 고정 월 예산을 생성하면 개발자가 할당된 예산을 초과하지 못하도록 제한할 수 있다. 
  - 이는 회사가 AWS 비용을 관리하는데 도움이 된다.
- D: IAM 정책을 사용하여 비용이 많이 드는 서비스 및 구성 요소에 대한 액세스를 거부하면 개발자가 의도하지 않게 비용이 많이 드는 서비스를 사용하지 못하도록 제한할 수 있다.
  - 이는 회사의 비용을 절감하는데 도움이 된다.
- F: 예산 금액에 도달하면 SNS 알림을 보내는 AWS 예산 알림 작업을 생성하면 개발자가 예산 제한에 가까이 다가갔을 때 알림을 받을 수 있다.
  - 또한 람다 함수를 호출하여 알림을 기반으로 자동 조치를 취할 수 있다.
- A: SCP를 사용하여 고정된 월간 계정 사용 제한을 설정할 수 있지만 이는 개발자가 사용할 수 있는 서비스 유형에 대한 제한을 제공하지 않는다.
- C: SCP를 사용하여 비용이 많이 드는 서비스 및 구성 요소에 대한 액세스를 거부할 수 있지만, IAM 정책만큼 유연하지 않고, 예산 관리 기능을 제공하지 않는다.
- E: 예산 금액에 도달하면 서비스를 종료하는 AWS 예산 알림 작업을 생성하면 예산 초과를 방지할 수 있지만 개발자에게 서비스 종료 전에 알림을 제공하지 않아 서비스 중단으로 이어질 수 있다.

---

#### 문제

- 회사에는 Source라는 AWS 계정에 애플리케이션이 있습니다. 계정이 AWS Organizations의 조직에 있습니다. 애플리케이션 중 하나는 AWS Lambda 함수를 사용하고 Amazon Aurora 데이터베이스에 인벤토리 데이터를 저장합니다. 
- 애플리케이션은 배포 패키지를 사용하여 Lambda 함수를 배포합니다. 회사는 Aurora에 대한 자동 백업을 구성했습니다. 회사는 Lambda 함수와 Aurora 데이터베이스를 Target이라는 새 AWS 계정으로 마이그레이션하려고 합니다. 
- 애플리케이션은 중요한 데이터를 처리하므로 회사는 가동 중지 시간을 최소화해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?

#### 보기

- A: 소스 계정에서 Lambda 함수 배포 패키지를 다운로드합니다. 배포 패키지를 사용하고 Target 계정에서 새 Lambda 함수를 생성합니다. 자동화된 Aurora DB 클러스터 스냅샷을 Target 계정과 공유합니다.
- B: 소스 계정에서 Lambda 함수 배포 패키지를 다운로드합니다. 배포 패키지를 사용하고 Target 계정에서 새 Lambda 함수를 생성합니다. AWS Resource Access Manager (AWS RAM)을 사용하여 Aurora DB 클러스터를 대상 계정과 공유합니다. Aurora DB 클러스터를 복제할 수 있는 대상 계정 권한을 부여합니다.
- C: AWS Resource Access Manager(AWS RAM)를 사용하여 Lambda 함수와 Aurora DB 클러스터를 Target 계정과 공유합니다. Aurora DB 클러스터를 복제할 수 있는 대상 계정 권한을 부여합니다.
- D: AWS Resource Access Manager(AWS RAM)를 사용하여 Lambda 기능을 Target 계정과 공유합니다. 자동화된 Aurora DB 클러스터 스냅샷을 Target 계정과 공유합니다.

#### 정답

- 정답: B
- B는 AWS RAM과 자동화된 백업을 함께 사용하여 가동 중지 시간을 최소화하면서 람다 함수와 Aurora 데이터베이스를 Target 계정으로 마이그레이션합니다.
  - 이 솔루션에서는 람다 함수 배포 패키지가 원본 계정에서 다운로드되어 대상 계정에서 새 람다 함수를 생성하는데 사용된다.
  - Aurora DB 클러스터는 AWS RAM을 사용하여 대상 계정과 공유되며 대상 계정에는 Aurora DB 클러스터를 복제할 수 있는 권한이 부여되어 대상 계정에 Aurora 데이터베이스가 소스 계정에서 계속 사용되는 동안 대상 계정이 복제된 Aurora 데이터베이스를 사용할 수 있으므로 가동 중지 시간을 최소화하면서 데이터를 대상 계정으로 마이그레이션할 수 있다.
- C는 데이터 마이그레이션 방법을 지정하지 않고 원본 계정과 대상 계정이 동일한 데이터를 공유하지 않기 때문에 가동 중지 시간을 발생시키므로 최선의 솔류션이 아니다.
- 람다만 공유하는 경우 마이그레이션하지 않는 것이며 람다는 RAM 공유 가능 리소스가 아니다.

---

#### 문제

- 회사는 Amazon EC2 인스턴스에서 Python 스크립트를 실행하여 데이터를 처리합니다. 스크립트는 10분마다 실행됩니다. 스크립트는 Amazon S3 버킷에서 파일을 수집하고 파일을 처리합니다. 
- 평균적으로 스크립트는 각 파일을 처리하는 데 약 5분 정도 걸립니다. 스크립트는 스크립트가 이미 처리한 파일을 다시 처리하지 않습니다. 회사는 Amazon CloudWatch 지표를 검토한 결과 파일 처리 속도로 인해 EC2 인스턴스가 약 40%의 시간 동안 유휴 상태임을 확인했습니다. 
- 회사는 워크로드의 가용성과 확장성을 높이려고 합니다. 또한 회사는 장기적인 관리 오버헤드를 줄이고 싶어합니다.
- 이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?

#### 보기

- A: 데이터 처리 스크립트를 AWS Lambda 함수로 마이그레이션합니다. 회사가 객체를 업로드할 때 S3 이벤트 알림을 사용하여 Lambda 함수를 호출하여 객체를 처리합니다.
- B: Amazon Simple Queue Service(Amazon SQS) 대기열을 생성합니다. SQS 대기열에 이벤트 알림을 보내도록 Amazon S3를 구성합니다. 최소 1개의 인스턴스 크기로 EC2 Auto Scaling 그룹을 생성합니다. SQS 대기열을 폴링하도록 데이터 처리 스크립트를 업데이트합니다. SQS 메시지가 식별하는 S3 객체를 처리합니다.
- C: 데이터 처리 스크립트를 컨테이너 이미지로 마이그레이션합니다. EC2 인스턴스에서 데이터 처리 컨테이너를 실행합니다. 새 객체에 대해 S3 버킷을 폴링하고 결과 객체를 처리하도록 컨테이너를 구성합니다.
- D: 데이터 처리 스크립트를 AWS Fargate의 Amazon Elastic Container Service(Amazon ECS)에서 실행되는 컨테이너 이미지로 마이그레이션합니다. 컨테이너가 파일을 처리할 때 Fargate RunTaskAPI 작업을 호출하는 AWS Lambda 함수를 생성합니다. S3 이벤트 알림을 사용하여 Lambda 함수를 호출합니다.

#### 정답

- 정답: D (A가 가장 투표율이 높음)
- 각 파일을 처리하는데 5분이 소요되고 EC2 인스턴스는 60%의 시간 동안 파일을 처리하고 있다. 이러한 시나리오에서는 람다 사용에 대한 비용이 많이 발생한다.
- 지속적으로 실행되는 Fargate도 절반의 시간만 실행하는 람다보다 저렴하므로 장기 실행 작업 로드는 람다에서 비용 효율적이지 않다.
  - 따라서 Fargate를 사용하는 것이 가장 비용 효율적인 솔루션이며 5분 동안 람다를 실행하는 것은 비용 효율적이지 않다.

---

#### 문제

- 회사에는 단일 AWS 계정이 있는 환경이 있습니다. 솔루션 아키텍트는 AWS Management Console에 대한 액세스 측면에서 회사가 구체적으로 개선할 수 있는 사항을 권장하기 위해 환경을 검토하고 있습니다. 
- 회사의 IT 지원 작업자는 현재 관리 작업을 위해 콘솔에 액세스하여 해당 직무에 매핑된 명명된 IAM 사용자를 인증합니다. IT 지원 작업자는 더 이상 Active Directory와 IAM 사용자 계정을 모두 유지하기를 원하지 않습니다. 
- 그들은 기존 Active Directory 자격 증명을 사용하여 콘솔에 액세스할 수 있기를 원합니다. 솔루션 아키텍트는 AWS IAM Identity Center(AWS Single Sign-On)를 사용하여 이 기능을 구현합니다.
- 이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?

#### 보기

- A: AWS Organizations에서 조직을 생성합니다. 조직에서 IAM ID 센터 기능을 활성화합니다. 회사의 온프레미스 Active Directory에 대한 양방향 신뢰를 사용하여 Microsoft Active Directory용 AWS 디렉터리 서비스(AWS Managed Microsoft AD)에서 디렉터리를 생성하고 구성합니다. IAM 자격 증명 센터를 구성하고 AWS Managed Microsoft AD 디렉터리를 자격 증명 소스로 설정합니다. 권한 세트를 생성하고 이를 AWS Managed Microsoft AD 디렉터리 내의 기존 그룹에 매핑합니다.
- B: AWS Organizations에서 조직을 생성합니다. 조직에서 IAM ID 센터 기능을 활성화합니다. 회사의 온프레미스 Active Directory에 연결하기 위한 AD 커넥터를 생성하고 구성합니다. IAM ID 센터를 구성하고 AD 커넥터를 ID 소스로 선택합니다. 권한 집합을 만들고 이를 회사 Active Directory 내의 기존 그룹에 매핑합니다.
- C: AWS Organizations에서 조직을 생성합니다. 조직의 모든 기능을 활성화합니다. 회사의 온프레미스 Active Directory에 대한 양방향 신뢰를 사용하여 Microsoft Active Directory용 AWS 디렉터리 서비스(AWS Managed Microsoft AD)에서 디렉터리를 생성하고 구성합니다. IAM 자격 증명 센터를 구성하고 AWS Managed Microsoft AD 디렉터리를 자격 증명 소스로 선택합니다. 권한 세트를 생성하고 이를 AWS Managed Microsoft AD 디렉터리 내의 기존 그룹에 매핑합니다.
- D: AWS Organizations에서 조직을 생성합니다. 조직의 모든 기능을 활성화합니다. 회사의 온프레미스 Active Directory에 연결하기 위한 AD 커넥터를 생성하고 구성합니다. IAM ID 센터를 구성하고 AD 커넥터를 ID 소스로 설정합니다. 권한 집합을 만들고 이를 회사 Active Directory 내의 기존 그룹에 매핑합니다.

#### 정답

- 정답: D
- D 옵션은 먼저 AWS Organizations의 모든 기능을 활성화한 다음 회사의 온프레미스 Active Directory에 연결하기 위한 AD 커넥터를 생성 및 구성한다.
  - 그런 다음 IAM ID 센터(AWS SSO)를 구성하고 AD 커넥터를 ID 소스로 설정하여 IT 지원 작업자가 기존 Active Directory 자격 증명을 사용하여 콘솔에 액세스할 수 있도록 한다.
  - 마지막으로 권한 집합을 만들고 이를 회사 Active Directory 내의 기존 그룹에 매핑한다.
  - 이러한 솔루션은 AWS Directory Service에서 새 디렉터리를 생성하지 않아도 되므로 비용 효율적이다.
- AWS Organizations에는 모든 기능 활성화(기본값) 및 통합 결제라는 두 가지 기능 모드가 있다. 
  - AWS Organizations는 기능 모드 선택에 관계 없이 무료다.
  - 또한 모든 기능 활성화와 통합 결제 두 가지 기능 모드만 있기 때문에 IAM ID 센터 기능을 따로 활성화할 수 없다.

---

#### 문제

- 회사는 단일 AWS 계정에서 여러 워크로드를 실행하고 있습니다. 새로운 회사 정책에는 엔지니어가 승인된 리소스만 프로비저닝할 수 있으며 엔지니어가 이러한 리소스를 프로비저닝하려면 AWS CloudFormation을 사용해야 한다고 명시되어 있습니다. 
- 솔루션 아키텍트는 엔지니어가 액세스에 사용하는 IAM 역할에 새로운 제한을 적용하는 솔루션을 생성해야 합니다.
- 솔루션 설계자는 솔루션을 만들기 위해 무엇을 해야 합니까?

#### 보기

- A: 승인된 리소스가 포함된 AWS CloudFormation 템플릿을 Amazon S3 버킷에 업로드합니다. Amazon S3 및 AWS CloudFormation에 대한 액세스만 허용하도록 엔지니어의 IAM 역할에 대한 IAM 정책을 업데이트합니다. AWS CloudFormation 템플릿을 사용하여 리소스를 프로비저닝합니다.
- B: 승인된 리소스 및 AWS CloudFormation의 프로비저닝만 허용하는 권한으로 엔지니어의 IAM 역할에 대한 IAM 정책을 업데이트합니다. AWS CloudFormation 템플릿을 사용하여 승인된 리소스로 스택을 생성합니다.
- C: AWS CloudFormation 작업만 허용하는 권한으로 엔지니어의 IAM 역할에 대한 IAM 정책을 업데이트합니다. 승인된 리소스를 프로비저닝할 수 있는 권한이 있는 새 IAM 정책을 생성하고 해당 정책을 새 IAM 서비스 역할에 할당합니다. 스택 생성 중에 AWS CloudFormation에 IAM 서비스 역할을 할당합니다.
- D: AWS CloudFormation 스택에 리소스를 프로비저닝합니다. 엔지니어의 IAM 역할에 대한 IAM 정책을 업데이트하여 자신의 AWS CloudFormation 스택에 대한 액세스만 허용합니다.

#### 정답

- 정답: C
- C는 AWS CloudFormation과 관련된 작업만 허용하도록 엔지니어 IAM 역할을 업데이트하여 CloudFormation 외부에서 AWS 리소스를 직접 프로비저닝하거나 수정하는 것을 효과적으로 방지하는 작업이 포함된다.
  - 템플릿을 실행할 때, CloudFormation이 가정하는 서비스 역할(승인된 리소스를 프로비저닝할 수 있는 권한 포함)을 생성하면 CloudFormation을 통해 승인된 리소스만 프로비저닝하도록 적용된다.
  - 이러한 설정은 명확한 권한 분리를 제공한다.
  - 엔지니어는 CloudFormation 스택을 관리할 수 있지만 CloudFormation 템플리세 정의되고 서비스 역할에서 허용하지 않는 한 리소스를 직접 생성할 수 없다.
- B에서는 승인된 리소스 및 CloudFromation 작업의 프로비저닝만 허용하도록 IAM 정책을 업데이트할 것을 제안한다.
  - 이러한 접근 방식은 이론적으로 IAM 정책의 특정 AWS 서비스에 대해 허용되는 작업을 명시적으로 나열함으로써 작동할 수 있다.
  - 그러나 유지 관리가 어료울 수 있으며 정책의 특수성에 따라 CloudFormation 외부의 작업을 실수로 허용할 수도 있다.

---

#### 문제

- example Corp.에는 온프레미스 데이터 센터가 있고, example Corp. AWS 계정에 VPC A라는 이름의 VPC가 있습니다. 온프레미스 네트워크는 AWS Site-To-Site VPN을 통해 VPC A에 연결됩니다. 
- 온프레미스 서버는 VPC A에 올바르게 액세스할 수 있습니다. 예시 회사는 방금 VPC B라는 VPC가 있는 AnyCompany를 인수했습니다. 이러한 네트워크 간에는 IP 주소가 중복되지 않습니다. 
- example Corp.는 VPC A와 VPC B를 피어링했습니다. example Corp.는 온프레미스 서버에서 VPC B로 연결하려고 합니다. example Corp.는 네트워크 ACL과 보안 그룹을 올바르게 설정했습니다.
- 최소한의 운영 노력으로 이 요구 사항을 충족할 수 있는 솔루션은 무엇입니까?

#### 보기

- A: 전송 게이트웨이를 생성합니다. Site-to-Site VPN, VPC A 및 VPC B를 전송 게이트웨이에 연결합니다. 모든 네트워크의 전송 게이트웨이 라우팅 테이블을 업데이트하여 다른 모든 네트워크에 대한 IP 범위 경로를 추가합니다.
- B: 전송 게이트웨이를 생성합니다. 온프레미스 네트워크와 VPC B 사이에 Site-to-Site VPN 연결을 생성하고 VPN 연결을 Transit Gateway에 연결합니다. 피어링된 VPC로 트래픽을 전달하는 경로를 추가하고, 클라이언트에게 VPC A와 B에 대한 액세스 권한을 부여하는 권한 부여 규칙을 추가합니다.
- C: 세 네트워크 모두에 대해 Site-to-Site VPN과 두 VPC의 라우팅 테이블을 업데이트합니다. 세 네트워크 모두에 대해 BGP 전파를 구성합니다. BGP 전파가 완료될 때까지 최대 5분 동안 기다립니다.
- D: VPC A와 VPC B를 포함하도록 Site-to-Site VPN의 가상 프라이빗 게이트웨이 정의를 수정합니다. 두 VPC 간에 가상 프라이빗 게이트웨이의 두 라우터를 분할합니다.

#### 정답

- 정답: A
- 전송 게이트웨이를 사용하여 온프레미스 네트워크, VPC A 및 VPC B를 연결할 수 있다.
  - 전송 게이트웨이는 여러 네트워크 간에 트래픽을 안전하게 라우팅하는 중앙 허브 역할을 한다.
  - 모든 네트워크의 전송 게이트웨이 라우팅 테이블을 업데이트하여 다른 모든 네트워크에 대한 IP 범위 경로를 추가한다.
- C에서 언급하고 있는 피어링이 엣지간 라우팅은 허용되지 않으며 전파되지 않는다.
- D에서 언급하고 있는 가상 프라이빗 게이트웨이는 단일 VPC에만 해당된다.
- B에서도 전송 게이트웨이를 언급하고 있지만 전송 게이트웨이를 잘못된 방식으로 사용하고 있으며, 전송 게이트웨이의 핵심 목적은 상호 연결성을 확보하는 것이다.

---

#### 문제

- 한 회사는 최근 플랫폼 변경 전략을 사용하여 온프레미스 데이터 센터에서 AWS 클라우드로의 마이그레이션을 완료했습니다. 마이그레이션된 서버 중 하나는 중요한 애플리케이션이 의존하는 기존 SMTP(Simple Mail Transfer Protocol) 서비스를 실행하고 있습니다. 
- 애플리케이션은 회사 고객에게 아웃바운드 이메일 메시지를 보냅니다. 레거시 SMTP 서버는 TLS 암호화를 지원하지 않으며 TCP 포트 25를 사용합니다. 애플리케이션은 SMTP만 사용할 수 있습니다.
- 회사는 Amazon Simple Email Service(Amazon SES)를 사용하고 기존 SMTP 서버를 폐기하기로 결정했습니다. 회사는 SES 도메인을 생성하고 검증했습니다. 회사는 SES 제한을 해제했습니다.
- Amazon SES에서 이메일 메시지를 보내도록 애플리케이션을 수정하려면 회사는 어떻게 해야 합니까?

#### 보기

- A: TLS 래퍼를 사용하여 Amazon SES에 연결하도록 애플리케이션을 구성합니다. ses:SendEmail 및 ses:SendRawEmail 권한이 있는 IAM 역할을 생성합니다. IAM 역할을 Amazon EC2 인스턴스에 연결합니다.
- B: STARTTLS를 사용하여 Amazon SES에 연결하도록 애플리케이션을 구성합니다. Amazon SES SMTP 자격 증명을 얻습니다. 자격 증명을 사용하여 Amazon SES에 인증합니다.
- C: SES API를 사용하여 이메일 메시지를 보내도록 애플리케이션을 구성합니다. ses:SendEmail 및 ses:SendRawEmail 권한이 있는 IAM 역할을 생성합니다. IAM 역할을 Amazon SES의 서비스 역할로 사용합니다.
- D: AWS SDK를 사용하여 이메일 메시지를 보내도록 애플리케이션을 구성합니다. Amazon SES용 IAM 사용자를 생성합니다. API 액세스 키를 생성합니다. 액세스 키를 사용하여 Amazon SES에 인증합니다.

#### 정답

- 정답: B
- [공식 문서](https://docs.aws.amazon.com/ses/latest/dg/smtp-connect.html)
- Amazon SES는 TLS를 사용하여 기존의 안전하지 않은 연결을 보안 연결로 업그레이드하는데 사용되는 프로토콜 명령인 STARTTLS를 지원한다.
  - 레거시 SMTP 레거시 서버는 TLS를 지원하지 않으며 STARTTLS를 사용하여 보안 연결을 시작할 수 있으므로 이는 매우 중요하다.
- A에서 언급하고 있는 TLS 래퍼는 더 이상 권장되지 않으며 STARTTLS는 더 안전하고 더 나은 옵션이다.

---

#### 문제

- 한 회사가 최근 다른 여러 회사를 인수했습니다. 각 회사에는 청구 및 보고 방법이 다른 별도의 AWS 계정이 있습니다. 인수 회사는 모든 계정을 AWS Organizations의 하나의 조직으로 통합했습니다. 
- 그러나 인수 회사는 모든 팀에 의미 있는 그룹이 포함된 비용 보고서를 생성하는 데 어려움을 겪었습니다. 인수 회사의 재무팀에는 자체 관리 애플리케이션을 통해 모든 회사의 비용을 보고할 수 있는 솔루션이 필요합니다.
- 어떤 솔루션이 이러한 요구 사항을 충족합니까?

#### 보기

- A: 조직에 대한 AWS 비용 및 사용 보고서를 생성합니다. 보고서에서 태그와 비용 범주를 정의합니다. Amazon Athena에서 테이블을 생성합니다. Athena 테이블을 기반으로 Amazon QuickSight 데이터세트를 생성합니다. 데이터세트를 재무팀과 공유하세요.
- B: 조직에 대한 AWS 비용 및 사용 보고서를 생성합니다. 보고서에서 태그와 비용 범주를 정의합니다. 재무 부서에서 보고서를 작성하는 데 사용할 특수 템플릿을 AWS Cost Explorer에서 생성합니다.
- C: AWS Price List Query API로부터 지출 정보를 수신하는 Amazon QuickSight 데이터세트를 생성합니다. 데이터세트를 재무팀과 공유하세요.
- D: AWS Price List Query API를 사용하여 계정 지출 정보를 수집합니다. 재무 부서에서 보고서를 작성하는 데 사용할 특수 템플릿을 AWS Cost Explorer에서 생성합니다.

#### 정답

- 정답: A
- 조직에 대한 AWS 비용 및 사용 보고서를 생성한다. 이 보고서는 모든 인수 회사의 비용을 하나의 보고서에 통합한다. 보고서에서 태그와 비용 범주를 정의한다.
  - 이를 통해 재무팀은 특정 팀 또는 비즈니스 영역과 관련된 비용을 쉽게 식별할 수 있다.
  - Amazon Athena에서 테이블을 생성하고 테이블은 보고서 데이터를 저장한다.
  - Athena 테이블을 기반으로 Amazon QuickSight 데이터세트를 생성한다. 이 데이터세트는 재무팀이 사용자 정의 보고서와 대시보드를 만들 수 있도록 한다.
  - 데이터 세트를 재무팀과 공유한다. 이를 통해 재무팀은 모든 회사의 비용을 통찰력 있게 보고하고 분석할 수 있다.
- 옵션 B에서 언급하고 있는 Cost Explorer 템플릿은 한정적인 기능을 제공하며 QuickSIght는 더 많은 유연성과 사용자 정의 기능을 제공한다.
- 옵션 C에서 언급하고 있는 Price List Query API는 실제 지출 데이터를 제공하지 않으며, Cost & Usage Report는 실제 지출 데이터를 제공한다.

---

#### 문제 (Hard)

- 한 회사에서 사용자가 문서를 업로드하는 전자 문서 관리 시스템을 구축하고 있습니다. 애플리케이션 스택은 완전히 서버리스이며 eu-central-1 지역의 AWS에서 실행됩니다. 
- 시스템에는 Amazon S3를 원본으로하여 제공하기 위해 Amazon CloudFront 배포를 사용하는 웹 애플리케이션이 포함되어 있습니다. 웹 애플리케이션은 Amazon API Gateway 지역 엔드포인트와 통신합니다. 
- API Gateway API는 Amazon Aurora Serverless 데이터베이스에 메타데이터를 저장하고 문서를 S3 버킷에 저장하는 AWS Lambda 함수를 호출합니다.
- 회사는 꾸준히 성장하고 있으며 최대 고객과의 개념 증명을 완료했습니다. 회사는 유럽 이외의 지역에서 대기 시간을 개선해야 합니다.
- 이러한 요구 사항을 충족하는 작업 조합은 무엇입니까? (2개를 선택하세요.)

#### 보기

- A: S3 버킷에서 S3 Transfer Acceleration을 활성화합니다. 웹 애플리케이션이 Transfer Acceleration 서명된 URL을 사용하는지 확인하십시오.
- B: AWS Global Accelerator에서 액셀러레이터를 생성합니다. CloudFront 배포판에 액셀러레이터를 연결합니다.
- C: API Gateway 지역 엔드포인트를 엣지 최적화 엔드포인트로 변경합니다.
- D: 전 세계에 분산된 다른 두 위치에 전체 스택을 프로비저닝합니다. Aurora Serverless 클러스터에서 글로벌 데이터베이스를 사용합니다.
- E: Lambda 함수와 Aurora Serverless 데이터베이스 사이에 Amazon RDS 프록시를 추가합니다.

#### 정답

- 정답: A, C
- A: S3 버킷에서 S3 Transfer Acceleration을 활성화하고 웹 애플리케이션이 Transfer Acceleration 서명된 URL을 사용하는지 확인하면 S3 버킷으로의 문서 업로드가 가속화된다.
  - 이는 유럽 외부 사용자의 지연시간을 줄이는데 도움이 된다.
- C: API 게이트웨이 리전 엔드포인트를 엣지 최적화 엔드포인트로 변경하면 API 게이트웨이의 응답을 사용자에게 더 가까이 캐싱하여 회사가 대기 시간을 개선하는데 도움이 된다.
- B: AWS Global Accelerator에서 액셀러레이터를 생성하고 이를 CloudFront 배포에 연결하는 것은 사용자 위치에 따라 트래픽을 최적의 엔드포인트로 라우팅하는데만 도움이 되므로 이 시나리오에서는 도움이 되지 않는다.
- D: 전 세계에 분산된 다른 두 위치에 전체 스택을 프로비저닝하고 Aurora Serverless 클러스터에서 글로벌 데이터베이스를 사용하면 대기 시간을 줄이는데 도움이 되지만 구현 및 관리가 복잡해진다.
- 리전 엔드포인트 특징은 아래와 같다.
  - API 호출은 API가 배포된 리전에서 처리된다.
  - API 호출은 리전 간 네트워크 지연을 경험할 수 있다.
  - API는 배포된 리전에서만 사용할 수 있다.
  - 모든 API Gateway 기능을 지원한다.
  - API 호출에 대한 요금이 부과된다.
  - 동일 리전 내에서 API를 사용하는 경우 적합하다.
- 엣지 최적화 엔드포인트의 특징은 아래와 같다.
  - API 호출은 AWS CloudFront 네트워크의 가장 가까운 엣지 위치에서 처리된다.
  - API 호출은 사용자와 가까운 엣지 위치에서 처리되므로 지연 시간이 줄어든다.
  - API는 전 세계 CloudFront 네트워크에서 사용할 수 있다.
  - 일부 API Gateway 기능은 지원하지 않는다.
  - API 호출 및 CloudFront 데이터 전송에 대한 요금이 부과된다.
  - 전 세계 사용자에게 API를 제공하고 지연 시간을 줄여야 하는 경우 적합하다.

---

#### 문제

- 한 회사는 Amazon S3를 사용하여 다양한 스토리지 클래스에 파일과 이미지를 저장합니다. 회사의 S3 비용은 지난 한 해 동안 크게 증가했습니다.
- 솔루션 설계자는 지난 12개월 동안의 데이터 추세를 검토하고 개체에 적합한 스토리지 클래스를 식별해야 합니다.
- 어떤 솔루션이 이러한 요구 사항을 충족합니까?

#### 보기

- A: 지난 12개월간 S3 사용에 대한 AWS 비용 및 사용 보고서를 다운로드하세요. 비용 절감을 위한 AWS Trusted Advisor 권장 사항을 검토하십시오.
- B: S3 스토리지 클래스 분석을 사용하십시오. 데이터 추세를 Amazon QuickSight 대시보드로 가져와 스토리지 추세를 분석합니다.
- C: Amazon S3 스토리지 렌즈를 사용하십시오. 스토리지 추세에 대한 고급 측정항목을 포함하도록 기본 대시보드를 업그레이드하세요.
- D: S3용 액세스 분석기를 사용합니다. 지난 12개월 동안의 S3용 액세스 분석기 보고서를 다운로드하세요. .csv 파일을 Amazon QuickSight 대시보드로 가져옵니다.

#### 정답

- 정답: C
- C: 객체 스토리지 사용량 및 활동 추세에 대한 조직 전체의 가시성을 제공하는 S3 Storage Lens를 사용하는 것을 의미한다.
  - 고급 지표 및 권장 사항을 포함하도록 업그레이드하면 사용자는 S3 리소스 전반에 걸쳐 스토리지 비용을 최적화하는데 도움이 되는 자세한 통찰력에 액세스할 수 있다.
  - S3 스토리지 렌즈는 실제 사용 패턴을 기반으로 적절한 스토리지 클래스에 대해 직접 정보를 제공할 수 있는 대시보드 보기와 지표를 제공하므로 명시된 요구 사항에 대한 포괄적인 솔루션이 된다.
- B: 스토리지 클래스 분석은 표준 및 표준 IA 스토리지 클래스에 대한 권장 사항을 제공하지만, 데이터 추세는 제공하지 않는다.
  - 즉, 표준에서 표준 IA로의 권장 사항에만 사용된다.

---

#### 문제

- 회사의 NAT 게이트웨이에 대해 활성화된 VPC 흐름 로그가 있습니다. 회사에는 프라이빗 Amazon EC2 인스턴스로 향하는 퍼블릭 IP 주소 198.51.100.2에서 들어오는 인바운드 트래픽에 대해 Action = ACCEPT가 표시됩니다.
- 솔루션 설계자는 트래픽이 인터넷에서 원치 않는 인바운드 연결을 나타내는지 여부를 확인해야 합니다. VPC CIDR 블록의 처음 두 옥텟은 203.0입니다.
- 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 단계를 수행해야 합니까?

#### 보기

- A: AWS CloudTrail 콘솔을 엽니다. NAT 게이트웨이의 탄력적 네트워크 인터페이스와 프라이빗 인스턴스의 탄력적 네트워크 인터레이스가 포함된 로그 그룹을 선택합니다. 쿼리를 실행하여 "like 203.0"으로 설정된 대상 주소와 "like 198.51.100.2"로 설정된 소스 주소로 필터링합니다. stats 명령을 실행하여 소스 주소와 대상 주소로 전송된 바이트의 합계를 필터링합니다.
- B: Amazon CloudWatch 콘솔을 엽니다. NAT 게이트웨이의 탄력적 네트워크 인터페이스와 프라이빗 인스턴스의 탄력적 네트워크 인터페이스가 포함된 로그 그룹을 선택합니다. 쿼리를 실행하여 "like 203.0"으로 설정된 대상 주소와 "like 198.51.100.2"로 설정된 소스 주소로 필터링합니다. stats 명령을 실행하여 소스 주소와 대상 주소로 전송된 바이트의 합계를 필터링합니다.
- C: AWS CloudTrail 콘솔을 엽니다. NAT 게이트웨이의 탄력적 네트워크 인터페이스와 프라이빗 인스턴스의 탄력적 네트워크 인터페이스가 포함된 로그 그룹을 선택합니다. 쿼리를 실행하여 "like 198.51.100.2"로 설정된 대상 주소와 "like 203.0"으로 설정된 소스 주소로 필터링합니다. stats 명령을 실행하여 소스 주소와 대상 주소로 전송된 바이트의 합계를 필터링합니다.
- D: Amazon CloudWatch 콘솔을 엽니다. NAT 게이트웨이의 탄력적 네트워크 인터페이스와 프라이빗 인스턴스의 탄력적 네트워크 인터페이스가 포함된 로그 그룹을 선택합니다. 쿼리를 실행하여 "like 198.51.100.2"로 설정된 대상 주소와 "like 203.0"으로 설정된 소스 주소로 필터링합니다. stats 명령을 실행하여 소스 주소와 대상 주소로 전송된 바이트의 합계를 필터링합니다.

#### 정답

- 정답: D
- [공식 문서](https://aws.amazon.com/premiumsupport/knowledge-center/vpc-analyze-inbound-traffic-nat-gateway/)
- CloudTrail은 API 호출만 기록하므로 A와 C는 정답이 될 수 없다.
- D는 올바른 로그 그룹을 선택하고 올바른 필터를 사용하여 원하는 정보를 얻을 수 있다. 또한 `stats` 명령을 사용하여 소스 주소와 대상 주소로 전송된 바이트의 합계를 필터링할 수 있다.
  - 옵션 D는 솔루션 설계자가 트래픽이 인터넷에서 원치 않는 인바운드 연결을 나타내는지 여부를 확인하는데 필요한 정보를 얻는 가장 적합한 옵션이다.

---

#### 문제

- 회사는 두 개의 별도 사업 단위로 구성됩니다. 각 사업부는 AWS Organizations의 단일 조직 내에 자체 AWS 계정을 가지고 있습니다. 각 사업부는 정기적으로 중요한 문서를 서로 공유합니다. 
- 공유를 용이하게 하기 위해 회사는 각 계정에 Amazon S3 버킷을 생성하고 S3 버킷 간에 저방향 복제를 구성했습니다. S3 버킷에는 수백만 개의 객체가 있습니다. 
- 최근 보안 감사를 통해 S3 버킷 모두 저장 시 암호화가 활성화되어 있지 않은 것으로 확인되었습니다. 회사 정책에 따라 모든 문서는 암호화된 상태로 저장되어야 합니다. 회사는 Amazon S3 관리형 암호화 키(SSE-S3)를 사용하여 서버 측 암호화를 구현하려고 합니다.
- 이러한 요구 사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?

#### 보기

- A: 두 S3 버킷 모두에서 SSE-S3을 켭니다. S3 배치 작업을 사용하여 동일한 위치에 객체를 복사하고 암호화합니다.
- B: 각 계정에 AWS Key Management Service(AWS KMS) 키를 생성합니다. 해당 AWS 계정의 해당 KMS 키를 사용하여 각 S3 버킷에서 AWS KMS 키(SSE-KMS)로 서버 측 암호화를 활성화합니다. AWS CLI에서 S3 복사 명령을 사용하여 기존 객체를 암호화합니다.
- C: 두 S3 버킷 모두에서 SSE-S3을 켭니다. AWS CLI에서 S3 복사 명령을 사용하여 기존 객체를 암호화합니다.
- D: 각 계정에 AWS Key Management Service(AWS KMS) 키를 생성합니다. 해당 AWS 계정의 해당 KMS 키를 사용하여 각 S3 버킷에서 AWS KMS 키(SSE-KMS)로 서버 측 암호화를 활성화합니다. S3 배치 작업을 사용하여 객체를 동일한 위치에 복사합니다.

#### 정답

- 정답: A
- 문제에서는 객체가 수백만 개라고 언급하고 있다. 객체의 수가 수백만 개인 경우 복제하는 것보다 배치 작업을 사용하는 것이 효율적이다.

---

#### 문제

- 한 회사가 AWS 클라우드에서 애플리케이션을 실행하고 있습니다. 애플리케이션은 Amazon S3 버킷에 대량의 구조화되지 않은 데이터를 수집하고 저장합니다. S3 버킷에는 수 테라바이트의 데이터가 포함되어 있으며 S3 Standard 스토리지 클래스를 사용합니다. 데이터 크기는 매일 수 기가바이트씩 증가합니다.
- 회사는 데이터를 쿼리하고 분석해야 합니다. 회사는 1년이 넘은 데이터에 접근하지 않습니다. 그러나 회사는 규정 준수를 위해 모든 데이터를 무기한 보관해야 합니다.
- 이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?

#### 보기

- A: S3 Select를 사용하여 데이터를 쿼리합니다. 1년이 넘은 데이터를 S3 Glacier Deep Archive로 전환하는 S3 수명 주기 정책을 생성합니다.
- B: Amazon Redshift Spectrum을 사용하여 데이터를 쿼리합니다. 1년이 넘은 10 S3 Glacier Deep Archive 데이터를 전환하는 S3 수명 주기 정책을 생성합니다.
- C: AWS Glue 데이터 카탈로그와 Amazon Athena를 사용하여 데이터를 쿼리합니다. 1년이 넘은 데이터를 S3 Glacier Deep Archive로 전환하는 S3 수명 주기 정책을 생성합니다.
- D: Amazon Redshift Spectrum을 사용하여 데이터를 쿼리합니다. 1년이 넘은 데이터를 S3 Intelligent-Tiering으로 전환하는 S3 수명 주기 정책을 생성합니다.

#### 정답

- 정답: C
- A: S3 Select를 사용하는 것은 S3에서 데이터를 필터링하는데는 좋지만 대량의 데이터를 쿼리하고 분석하는데는 적합한 솔루션이 아니다.
- B: Redshift Spectrum을 사용하여 S3에 저장된 데이터를 쿼리할 수 있지만 구조화되지 않은 데이터를 쿼리하기 위해 Athena를 사용하는 것만큼 비용 효율적이지는 않을 수 있다.
- C: 이 솔루션을 사용하면 Athena 및 Glue 데이터 카탈로그를 사용하여 S3 버킷의 데이터를 쿼리하고 분석할 수 있다.
  - Athena는 SQL을 사용하여 S3의 데이터를 분석할 수 있는 서버리스 대화형 쿼리 서비스다.
  - Glue 데이터 카탈로그는 S3에 저장된 데이터에 대한 테이블 정의를 저장하고 검색하는데 사용할 수 있는 관리형 메타데이터 저장소다.
  - 이러한 서비스를 함께 사용하면 대량의 구조화되지 않은 데이터를 쿼리하고 분석하는 비용 효율적인 방법을 제공할 수 있다.

---

#### 문제

- 솔루션 아키텍트는 새로운 Amazon S3 버킷에 저장될 객체에 대해 클라이언트 측 암호화 메커니즘을 구현해야 합니다. 솔루션 아키텍트는 이러한 목적으로 AWS Key Management Service(AWS KMS)에 저장되는 CMK를 생성했습니다.
- 솔루션 설계자는 다음 IAM 정책을 생성하여 IAM 역할에 연결했습니다.

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "DownloadUpload",
      "Action": [
        "s3:GetObject",
        "s3:GetObjectVersion",
        "s3:PutObject",
        "s3:PutObjectAcl"
      ],
      "Effect": "Allow",
      "Resource": "arn:aws:s3:::BucketName/*"
    },
    {
      "Sid": "KMSAccess",
      "Action": [
        "kms:Decrypt",
        "kms:Encrypt"
      ],
      "Effect": "Allow",
      "Resource": "arn:aws:kms:Region:Account:key/Key ID"
    }
  ]
}
```

- 테스트 중에 솔루션 설계자는 S3 버킷에서 기존 테스트 개체를 성공적으로 가져올 수 있었습니다. 그러나 새 개체를 업로드하려고 하면 오류 메시지가 발생했습니다. 
- 오류 메시지에는 작업이 금지되었다고 명시되어 있습니다. 모든 요구 사항을 충족하려면 솔루션 설계자가 IAM 정책에 어떤 작업을 추가해야 합니까?

#### 보기

- A: kms:GenerateDataKey
- B: kms:GetKeyPolicy
- C: kms:GetPublicKey
- D: kms:Sign

#### 정답

- 정답: A
- 새로운 객체를 업로드하려면 S3 버킷에 객체를 업로드하는 권한(`s3:PutObject`)외에 AWS KMS를 사용하여 객체를 암화화하는 권한도 필요하다.
  - `kms:GenerateDataKey`를 추가하여 사용자에게 AWS KMS를 사용하여 데이터 키를 생성하는 권한을 부여한다.

---

#### 문제

- 한 회사에서 웹 애플리케이션을 개발했습니다. 이 회사는 Application Load Balancer 뒤에 있는 Amazon EC2 인스턴스 그룹에서 애플리케이션을 호스팅하고 있습니다. 
- 회사는 애플리케이션의 보안 상태를 개선하기를 원하며 AWS WAF 웹 ACL을 사용할 계획입니다. 솔루션은 애플리케이션에 대한 합법적인 트래픽에 부정적인 영향을 주어서는 안 됩니다.
- 솔루션 설계자는 이러한 요구 사항을 충족하도록 웹 ACL을 어떻게 구성해야 합니까?

#### 보기

- A: 웹 ACL 규칙의 작업을 개수로 설정합니다. AWS WAF 로깅을 활성화합니다. 오탐지 요청을 분석합니다. 잘못된 긍정을 방지하려면 규칙을 수정하세요. 시간이 지남에 따라 웹 ACL 규칙의 작업을 개수에서 차단으로 변경합니다.
- B: 웹 ACL에서는 속도 기반 규칙만 사용하고 제한을 최대한 높게 설정합니다. 한도를 초과하는 모든 요청을 일시적으로 차단합니다. 요율 추적 범위를 좁히려면 중첩 규칙을 정의하세요.
- C: 웹 ACL 규칙의 동작을 차단으로 설정합니다. 웹 ACL에는 AWS 관리형 규칙 그룹만 사용하십시오. AWS WAF 샘플링 요청 또는 AWS WAF 로그와 함께 Amazon CloudWatch 지표를 사용하여 규칙 그룹을 평가합니다.
- D: 웹 ACL에서는 사용자 지정 규칙 그룹만 사용하고 작업을 허용으로 설정합니다. AWS WAF 로깅을 활성화합니다. 오탐지 요청을 분석합니다. 잘못된 긍정을 방지하려면 규칙을 수정하세요. 시간이 지남에 따라 웹 ACL 규칙의 작업을 허용에서 차단으로 변경합니다.

#### 정답

- 정답: A
- AWS WAF를 사용하면 "카운트" 모드에서 웹 ACL 규칙을 생성할 수 있으므로 트래픽을 실제로 차단하지 않고도 모니터링할 수 있다. 
  - 카운트 모드에서 AWS WAF는 특정 규칙과 일치하는 요청 수를 계산하지만 해당 요청을 차단하기 위해 어떠한 조치도 취하지 않는다.
  - 카운트 모드는 여러가지 면에서 유용할 수 있다.
- 트래픽을 차단하도록 활성화하기 전에 새 규칙을 생성하고 카운트 모드에서 테스트할 수 있다.
  - 이를 통해 거짓된 긍정이나 거짓된 부정의 위험 없이 규칙의 효율성을 평가할 수 있다.
- 카운트 모드를 사용하여 트래픽 패턴을 분석하고 잠재적인 보안 위협을 식별할 수 있다.
  - 특정 규칙과 일치하는 요청 수를 모니터링하면 공격이나 취약점을 나타낼 수 있는 패턴을 탐지할 수 있다.
- 카운트 모드는 특정 규칙이 시행되고 있음을 입증해야 하는 규정 준수 보고에 사용할 수 있다.
  - 규칙과 일치하는 요청 수를 계산하여 보안 정책이 준수되고 있다는 증거를 제공할 수 있다.

---

#### 문제

- 회사에는 AWS Organizations에 많은 AWS 계정이 있는 조직이 있습니다. 솔루션 아키텍트는 회사가 조직 내 AWS 계정에 대한 공통 보안 그룹 규칙을 관리하는 방법을 개선해야 합니다.
- 회사는 회사의 온프레미스 네트워크에 대한 액세스를 허용하기 위해 각 AWS 계정의 허용 목록에 공통 IP CIDR 범위 세트를 가지고 있습니다. 각 계정 내의 개발자는 보안 그룹에 새로운 IP CIDR 범위를 추가할 책임이 있습니다. 
- 보안팀에는 자체 AWS 계정이 있습니다. 현재 보안 팀은 허용 목록이 변경되면 다른 AWS 계정 소유자에게 알립니다. 솔루션 설계자는 모든 계정에 공통 CIDR 범위 집합을 배포하는 솔루션을 설계해야 합니다.
- 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

#### 보기

- A: 보안 팀의 AWS 계정에 Amazon Simple 알림 서비스(Amazon SNS) 주제를 설정합니다. 각 AWS 계정에 AWS Lambda 함수를 배포합니다. SNS 주제가 메시지를 수신할 때마다 실행되도록 Lambda 함수를 구성합니다. IP 주소를 입력으로 사용하고 이를 계정의 보안 그룹 목록에 추가하도록 Lambda 함수를 구성합니다. 보안팀에 SNS 주제에 메시지를 게시하여 변경 사항을 배포하도록 지시하세요.
- B: 조직 내의 각 AWS 계정에 새로운 고객 관리 접두사 목록을 생성합니다. 모든 내부 CIDR 범위로 각 계정의 접두사 목록을 채웁니다. 보안 그룹의 계정에 새로운 고객 관리형 접두사 목록 ID를 허용하도록 각 AWS 계정의 소유자에게 알립니다. 각 AWS 계정 소유자와 업데이트를 공유하도록 보안 팀에 지시하십시오.
- C: 보안 팀의 AWS 계정에 새로운 고객 관리 접두사 목록을 생성합니다. 모든 내부 CIDR 범위로 고객 관리 접두사 목록을 채웁니다. AWS Resource Access Manager를 사용하여 고객 관리형 접두사 목록을 조직과 공유합니다. 보안 그룹에서 새로운 고객 관리형 접두사 목록 ID를 허용하도록 각 AWS 계정의 소유자에게 알립니다.
- D: 조직의 각 계정에 IAM 역할을 생성합니다. 보안 그룹을 업데이트할 수 있는 권한을 부여합니다. 보안 팀의 AWS 계정에 AWS Lambda 함수를 배포합니다. 내부 IP 주소 목록을 입력으로 사용하고, 각 조직 계정의 역할을 맡고, 각 계정의 보안 그룹에 IP 주소 목록을 추가하도록 Lambda 함수를 구성합니다.

#### 정답

- 정답: C
- 이 솔루션은 보안 팀이 단일 고객 관리 접두사 목록을 생성 및 유지하고 AWS RAM을 사용하여 이를 조직과 공유해야 하므로 최소한의 운영 오버헤드로 요구 사항을 충족한다.
  - 그런 다음 각 AWS 계정의 소유자는 보안 그룹의 접두사 목록을 허용할 책임이 있으므로 변경 사항이 있을 때 보안 팀이 각 계정 소유자에게 수동으로 알릴 필요가 없다.
  - 또한 이 솔류션을 사용하면 각 계정에 별도의 람다 함수가 필요하지 않으므로 솔루션의 전반적인 복잡성이 줄어든다.
- A: 모든 AWS 계정에 람다 함수를 배포해야 하기 때문에 운영 오버헤드가 높고, 람다 함수는 오류 가능성이 있으며 디버깅이 어려울 수 있다.
- B: 각 AWS 계정 소유자에게 수동으로 업데이트를 알려야 하기 때문에 오류 가능성이 높다. 각 계정 소유자가 업데이트를 적용하는데 시간이 지연될 수 있다.
- D: 모든 AWS 계정에 IAM 역할을 생성해야 하기 때문에 관리가 복잡하다. 람다 함수는 오류 가능성이 있으며 디버깅이 어려울 수 있다.

---

#### 문제

- 회사는 직원들이 VPN을 사용하여 연결하면 집에서 원격으로 근무할 수 있도록 허용하는 새로운 정책을 도입했습니다. 회사는 여러 AWS 계정의 VPC를 사용하여 내부 애플리케이션을 호스팅하고 있습니다. 
- 현재 애플리케이션은 AWS Site-to-Site VPN 연결을 통해 회사의 온프레미스 사무실 네트워크에서 액세스할 수 있습니다. 회사의 기본 AWS 계정에 있는 VPC에는 다른 AWS 계정에 있는 VPC와 피어링 연결이 설정되어 있습니다.
- 솔루션 아키텍트는 직원이 재택근무하는 동안 사용할 수 있도록 확장 가능한 AWS 클라이언트 VPN 솔루션을 설계해야 합니다.
- 이러한 요구 사항을 충족하는 가장 비용 효율적인 솔루션은 무엇입니까?

#### 보기

- A: 각 AWS 계정에 클라이언트 VPN 엔드포인트를 생성합니다. 내부 애플리케이션에 대한 액세스를 허용하는 필수 라우팅을 구성합니다.
- B: 기본 AWS 계정에 클라이언트 VPN 엔드포인트를 생성합니다. 내부 애플리케이션에 대한 액세스를 허용하는 필수 라우팅을 구성합니다.
- C: 기본 AWS 계정에 클라이언트 VPN 엔드포인트를 생성합니다. 각 AWS 계정에 연결된 전송 게이트웨이를 프로비저닝합니다. 내부 애플리케이션에 대한 액세스를 허용하는 필수 라우팅을 구성합니다.
- D: 기본 AWS 계정에 클라이언트 VPN 엔드포인트를 생성합니다. 클라이언트 VPN 엔드포인트와 AWS Site-to-Site VPN 간의 연결을 설정합니다.

#### 정답

- 정답: B
- 여기서 중요하게 봐야할 부분은 기본 AWS 계정에 있는 VPC에는 다른 AWS 계정에 있는 VPC와 피어링 연결이 설정되어 있으며, 가장 비용 효율적인 솔루션을 찾는다는 점이다.
- A: 각 AWS 계정에 클라이언트 VPN 엔드포인트를 생성해야 하기 때문에 관리가 복잡하다. 여러 AWS 계정 간에 라우팅을 구성해야 하기 때문에 오류 가능성이 높다.
- B: 기본 AWS 계정에 단일 클라이언트 VPN 엔드포인트만 생성하면 관리가 간편하다. 모든 내부 애플리케이션에 대한 액세스를 허용하는 단일 라우팅 구성이 필요하다.
- C: 각 AWS 계정에 연결된 전송 게이트웨이를 프로비저닝해야 하기 때문에 비용이 많이 발생한다. 라우팅 구성이 더 복잡해진다.
- D: 기존 AWS Site-to-Site VPN 연결과 클라이언트 VPN 엔드포인트를 연결하는 것은 불필요한 복잡성을 추가한다. 관리가 더 어려워진다.

---

#### 문제

- 한 회사가 다중 계정 환경의 AWS에서 애플리케이션을 실행하고 있습니다. 회사의 영업팀과 마케팅팀은 AWS Organizations에서 별도의 AWS 계정을 사용합니다.
- 영업팀은 Amazon S3 버킷에 페타바이트 규모의 데이터를 저장합니다. 마케팅 팀은 데이터 시각화를 위해 Amazon QuickSight를 사용합니다. 마케팅 팀은 상태 팀이 S3 버킷에 저장하는 데이터에 액세스해야 합니다. 
- 회사는 AWS KMS(AWS Key Management Service) 키를 사용하여 S3 버킷을 암호화했습니다. 마케팅 팀은 마케팅 AWS 계정에 QuickSight 액세스를 제공하기 위해 QuickSight에 대한 IAM 서비스 역할을 이미 생성했습니다. 
- 회사에는 AWS 계정 전체에서 S3 버킷의 데이터에 대한 보안 액세스를 제공하는 솔루션이 필요합니다. 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

#### 보기

- A: 마케팅 계정에 새 S3 버킷을 생성합니다. 판매 계정에서 S3 복제 규칙을 생성하여 마케팅 계정의 새 S3 버킷에 객체를 복사합니다. 새 S3 버킷에 대한 액세스 권한을 부여하려면 마케팅 계정의 QuickSight 권한을 업데이트하세요.
- B: SCP를 생성하여 마케팅 계정에 S3 버킷에 대한 액세스 권한을 부여합니다. AWS Resource Access Manager(AWS RAM)를 사용하여 sates 계정의 KMS 키를 마케팅 계정과 공유합니다. S3 버킷에 대한 액세스 권한을 부여하려면 마케팅 계정의 QuickSight 권한을 업데이트하세요.
- C: 마케팅 계정의 S3 버킷 정책을 업데이트하여 QuickSight 역할에 대한 액세스 권한을 부여합니다. S3 버킷에 사용되는 암호화 키에 대한 KMS 권한을 생성합니다. QuickSight 역할에 암호 해독 액세스 권한을 부여합니다. S3 버킷에 대한 액세스 권한을 부여하려면 마케팅 계정의 QuickSight 권한을 업데이트하세요.
- D: 판매 계정에 IAM 역할을 생성하고 S3 버킷에 대한 액세스 권한을 부여합니다. 마케팅 계정에서 판매 계정의 IAM 역할을 맡아 S3 버킷에 액세스합니다. QuickSight 반복을 업데이트하여 영업 계정의 새 IAM 역할과 신뢰 관계를 생성합니다.

#### 정답

- 정답: D
- [관련 문서](https://medium.com/codebyte/cross-account-s3-object-copying-with-kms-encrypted-buckets-5ebabef8aa03)
- 판매 계정에 IAM 역할을 생성하고 S3 버킷에 대한 액세스 권한을 부여한다. 마케팅 계정에서 판매 계정의 IAM 역할을 맡아 S3 버킷에 액세스한다.
  - 영업 계정의 새 IAM 역할과 신뢰 관계를 생성하려면 QuickSight 역할을 업데이트해야 한다.
  - 이 솔루션은 마케팅 팀이 IAM 역할을 맡아 영업 계정의 S3 버킷에 있는 데이터에 액세스할 수 있도록 함으로써 요구 사항을 충족한다.
  - 이를 통해 데이터를 복사하거나 KMS 키를 공유할 필요가 없고, S3 버킷 정책을 사용하거나 KMS 권한 부여를 생성할 수 있다.
  - 이 솔루션을 사용하면 데이터를 복제하고 다시 암호화하지 않고도 버킷에 대해 동일한 액세스를 사용할 수 있다.

---

#### 문제

- 출판사의 디자인 팀은 전자상거래 웹 애플리케이션에서 사용하는 아이콘과 기타 정적 자산을 업데이트합니다. 회사는 회사의 프로덕션 계정에서 호스팅되는 Amazon S3 버킷의 아이콘과 자산을 제공합니다. 회사에서는 디자인 팀 구성원이 액세스할 수 있는 개발 계정도 사용합니다.
- 디자인 팀이 개발 계정의 정적 자산을 테스트한 후 디자인 팀은 프로덕션 계정의 S3 버킷에 자산을 로드해야 합니다. 솔루션 설계자는 원치 않는 변경 위험에 웹 애플리케이션의 다른 부분을 노출시키지 않고 디자인 팀에게 프로덕션 계정에 대한 액세스 권한을 제공해야 합니다.
- 이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (3개를 선택하세요.)

#### 보기

- A: 프로덕션 계정에서 S3 버킷에 대한 읽기 및 쓰기 액세스를 허용하는 새로운 IAM 정책을 생성하십시오.
- B: 개발 계정에서 S3 버킷에 대한 읽기 및 쓰기 액세스를 허용하는 새로운 IAM 정책을 생성합니다.
- C: 프로덕션 계정에서 역할을 생성하고 새 정책을 역할에 연결합니다. 개발 계정을 신뢰할 수 있는 엔터티로 정의합니다.
- D: 개발 계정에서 역할을 생성합니다. 역할에 새 정책을 연결합니다. 프로덕션 계정을 신뢰할 수 있는 엔터티로 정의합니다.
- E: 개발 계정에서 디자인 팀의 모든 IAM 사용자를 포함하는 그룹을 생성합니다. 프로덕션 계정의 역할에 대한 sts:AssumeRole 작업을 허용하도록 그룹에 다른 IAM 정책을 연결합니다.
- F: 개발 계정에서 디자인 팀의 모든 IAM 사용자를 포함하는 그룹을 생성합니다. 개발 계정의 역할에 대해 sts:AssumeRole 작업을 허용하도록 그룹에 다른 IAM 정책을 연결합니다.

#### 정답

- 정답: A, C, E
- A: 프로덕션 계정에서 S3 버킷에 대한 읽기 및 쓰기 액세스를 허용하는 새로운 IAM 정책을 생성하는 것을 올바른 선택이다.
- C: 프로덕션 계정에서 역할을 생성하고 새 정책을 역할에 연결하고 개발 계정을 신뢰할 수 있는 엔터티로 정의하는 것은 올바른 선택이다.
- E: 개발 계정에서 설계 팀의 모든 IAM 사용자를 포함하는 그룹을 생성하고 프로덕션 계정의 역할에 대한 `stsAssumeRole` 작업을 허용하도록 그룹에 다른 IAM 정책을 연결하는 것은 올바른 선택이다.
  - 그룹에서 프로덕션 계정에 생성된 역할을 맡아 프로덕션 계정의 S3 버킷에 액세스 권한을 부여한다.
- F: 개발 계정에서 디자인 팀의 모든 IAM 사용자를 포함하는 그룹을 생성하고 개발 계정의 역할에 대한 `sts:AssumeRole` 작업을 허용하기 위해 그룹에 다른 IAM 정책을 연결하는 것은 올바르지 않다.
  - S3 버킷에 액세스하려면 개발 계정이 아닌 프로덕션 계정의 역할을 맡아야 한다.

---

#### 문제

- 한 회사에서 AWS Elastic Beanstalk 및 Java를 사용하여 파일럿 애플리케이션을 개발했습니다. 개발 중 비용을 절감하기 위해 회사의 개발 팀은 애플리케이션을 단일 인스턴스 환경에 배포했습니다. 
- 최근 테스트에 따르면 애플리케이션이 예상보다 더 많은 CPU를 소비하는 것으로 나타났습니다. CPU 사용률은 정기적으로 85%를 초과하므로 일부 성능 병목 현상이 발생합니다.
- 솔루션 설계자는 회사가 애플리케이션을 프로덕션에 출시하기 전에 성능 문제를 완화해야 합니다.
- 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

#### 보기

- A: 새로운 Elastic Beanstalk 애플리케이션을 생성합니다. 로드 밸런싱된 환경 유형을 선택합니다. 모든 가용 영역을 선택합니다. 최대 CPU 사용률이 5분 동안 85%를 초과하는 경우 실행되는 확장 규칙을 추가합니다.
- B: 두 번째 Elastic Beanstalk 환경을 생성합니다. 트래픽 분할 배포 정책을 적용합니다. 평균 CPU 사용률이 5분 동안 85%를 초과하는 경우 새 환경으로 전달할 수신 트래픽의 비율을 지정합니다.
- C: 로드 밸런싱된 환경 유형을 사용하도록 기존 환경의 용량 구성을 수정합니다. 모든 가용 영역을 선택합니다. 평균 CPU 사용률이 5분 동안 85%를 초과하는 경우 실행되는 확장 규칙을 추가합니다.
- D: 로드 밸런싱 옵션을 사용하여 환경 재구축 작업을 선택합니다. 가용성 영역을 선택합니다. 총 CPU 사용률이 5분 동안 85%를 초과하는 경우 실행되는 확장 규칙을 추가합니다.

#### 정답

- 정답: C
- [공식 문서](https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features-managing-env-types.html)
- 새로운 환경을 구축하거나, 두 번째 환경을 생성하거나, 환경을 재구축하는 것은 시간이 오래걸리고 오버헤드가 발생한다. 
  - 기존 환경을 업데이트하는 것은 간단하고 효율적이다.

---

#### 문제

- 회사는 회사 데이터 센터에 있는 VM에 대해 복잡한 종속성을 갖는 Java 애플리케이션을 실행합니다. 응용 프로그램이 안정적입니다. 하지만 회사는 기술 스택을 현대화하고 싶어합니다. 
- 회사는 애플리케이션을 AWS로 마이그레이션하고 서버 유지 관리에 드는 관리 오버헤드를 최소화하려고 합니다.
- 최소한의 코드 변경으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

#### 보기

- A: AWS App2Container를 사용하여 애플리케이션을 AWS Fargate의 Amazon Elastic Container Service(Amazon ECS)로 마이그레이션합니다. Amazon Elastic Container Registry(Amazon ECR)에 컨테이너 이미지를 저장합니다. ECS 작업 실행 역할에 ECR 이미지 저장소에 대한 액세스 권한 10을 부여합니다. Application Load Balancer(ALB)를 사용하도록 Amazon ECS를 구성합니다. ALB를 사용하여 애플리케이션과 상호작용합니다.
- B: 애플리케이션 코드를 AWS Lambda에서 실행되는 컨테이너로 마이그레이션합니다. Lambda 통합을 통해 Amazon API Gateway REST API를 구축하세요. API 게이트웨이를 사용하여 애플리케이션과 상호 작용합니다.
- C: AWS App2Container를 사용하여 EKS 관리형 노드 그룹의 Amazon Elastic Kubernetes Service(Amazon EKS)로 애플리케이션을 마이그레이션합니다. Amazon Elastic Container Registry(Amazon ECR)에 컨테이너 이미지를 저장합니다. ECR 이미지 저장소에 액세스할 수 있는 권한을 EKS 노드에 부여하십시오. Amazon API Gateway를 사용하여 애플리케이션과 상호 작용합니다.
- D: 애플리케이션 코드를 AWS Lambda에서 실행되는 컨테이너로 마이그레이션합니다. Application Load Balancer(ALB)를 사용하도록 Lambda를 구성합니다. ALB를 사용하여 애플리케이션과 상호작용합니다.

#### 정답

- 정답: A
- AWS App2Container를 사용하여 애플리케이션을 Fargate의 ECS로 마이그레이션하고 ECR에 컨테이너 이미지를 저장하면 코드 변경과 필요한 관리 오버헤드가 최소화된다.
  - 이 옵션을 사용하면 회사는 ALB를 사용하여 애플리케이션과 상호 작용할 수 있으며 ECS 작업 실행 역할 권한을 사용하여 ECR 이미지 저장소에 액세스할 수 있다.
- B: 애플리케이션 코드를 람다에서 실행되는 컨테이너로 마이그레이션하려면 많은 코드 변경이 필요하다.
- C: EKS로 마이그레이션하는 경우 더 많은 관리 오버헤드가 발생한다.

---

#### 문제

- 한 소매 회사가 AWS 계정을 AWS Organizations 조직의 일부로 구성했습니다. 회사는 통합 청구를 설정하고 부서를 재무, 영업, 인사(HR), 마케팅 및 운영 OU에 매핑했습니다. 각 OU에는 부서 내 환경마다 하나씩 여러 개의 AWS 계정이 있습니다. 이러한 환경은 개발, 테스트, 사전 프로덕션 및 프로덕션입니다.
- HR 부서에서는 3개월 후에 출시될 새로운 시스템을 출시할 예정입니다. 준비 과정에서 HR 부서는 프로덕션 AWS 계정에서 여러 예약 인스턴스(RI)를 구입했습니다. HR 부서에서는 이 계정에 새 애플리케이션을 설치합니다. HR 부서에서는 다른 부서가 RI 할인을 공유할 수 없도록 하려고 합니다.
- 어떤 솔루션이 이러한 요구 사항을 충족합니까?

#### 보기

- A: HR 부서의 프로덕션 계정에 대한 AWS Billing and Cost Management 콘솔에서 RI 공유를 끄십시오.
- B: 조직에서 HR 부서의 프로덕션 AWS 계정을 제거합니다. 통합 결제 구성에만 계정 10을 추가하세요.
- C: AWS Billing and Cost Management 콘솔에서. 조직의 마스터 계정을 사용합니다. 10 HR 부서 프로덕션 AWS 계정에 대한 RI 공유를 비활성화합니다.
- D: 조직에 SCP를 생성하여 RI에 대한 액세스를 제한합니다. 다른 부서의 OU에 SCP를 적용합니다.

#### 정답

- 정답: C
- C: 이 솔루션에서는 조직의 마스터 계정을 사용하여 AWS Billing and Cost Management 콘솔에서 HR 부서의 프로덕션 AWS 계정에 대한 RI 공유를 끌 수 있다.
  - 이렇게 하면 다른 부서가 RI 할인을 공유할 수 없고 HR 부서는 중단 없이 새 시스템에 RI를 사용할 수 있다.
- A: HR 부서의 프로덕션 계정에서 RI 공유를 꺼도 다른 부서가 RI 할인을 공유하는 것을 막지 못한다.
- B: 조직에서 HR 부서의 프로덕션 AWS 계정을 제거하면 통합 결제에 문제가 발생할 수 있으며 다른 부서가 RI 할인을 공유하는 것을 방해하지 않는다.
- D: 마스터 계정이 RI 공유를 직접 끌 수 있고 다른 부서가 RI 할인을 공유하는 것을 방해하지 않기 때문에 RI에 대한 액세스를 제한하기 위해 조직에서 SCP를 생성할 필요가 없다.

---

#### 문제

- 한 회사에서 여러 AWS 계정에 걸쳐 AWS WAF 규칙을 관리하기 위해 AWS WAF 솔루션을 배포하려고 합니다. 계정은 AWS Organizations의 다양한 OU에서 관리됩니다.
- 관리자는 필요에 따라 관리형 AWS WAF 규칙 세트에서 계정이나 OU를 추가하거나 제거할 수 있어야 합니다. 또한 관리자는 모든 계정에서 규정을 준수하지 않는 AWS WAF 규칙을 자동으로 업데이트하고 해결할 수 있는 능력도 있어야 합니다.
- 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

#### 보기

- A: AWS Firewall Manager를 사용하여 조직 내 계정 전체에서 AWS WAF 규칙을 관리하십시오. AWS Systems Manager Parameter Store 매개변수를 사용하여 관리할 계정 번호와 OU를 저장합니다. 계정이나 OU를 추가하거나 제거하려면 필요에 따라 매개변수를 업데이트하세요. Amazon EventBridge 규칙을 사용하여 매개변수에 대한 변경 사항을 식별하고 AWS Lambda 함수를 호출하여 Firewall Manager 관리 계정의 보안 정책을 업데이트합니다.
- B: 선택한 OU의 모든 리소스가 AWS WAF 규칙을 연결하도록 요구하는 조직 전체에 AWS Config 규칙을 배포합니다. AWS Lambda를 사용하여 자동화된 수정 작업을 배포하여 규정을 준수하지 않는 리소스를 수정합니다. AWS Config 규칙이 적용되는 동일한 OU를 대상으로 하는 AWS CloudFormation 스택 세트를 사용하여 AWS WAF 규칙을 배포합니다.
- C: 조직의 마스터 계정에 AWS WAF 규칙을 생성합니다. AWS Lambda 환경 변수를 사용하여 관리할 계정 번호와 OU를 저장합니다. 계정이나 OU를 추가하거나 제거하려면 필요에 따라 환경 변수를 업데이트하세요. 회원 계정에서 교차 계정 IAM 역할을 생성합니다. Lambda 함수에서 AWS Security Token Service(AWS STS)를 사용하여 역할을 맡아 멤버 계정에서 AWS WAF 규칙을 생성하고 업데이트합니다.
- D: AWS Control Tower를 사용하여 조직 내 계정 전체에서 AWS WAF 규칙을 관리합니다. AWS Key Management Service(AWS KMS)를 사용하여 관리할 계정 번호와 OU를 저장합니다. 계정이나 OU를 추가하거나 제거하려면 필요에 따라 AWS KMS를 업데이트하세요. 회원 계정에 IAM 사용자를 생성합니다. 허용 AWS Control Tower 마스터 계정 액세스 키 및 보안 액세스 키를 사용하여 회원 계정에서 AWS WAF 규칙을 생성하고 업데이트합니다.

#### 정답

- 정답: A
- [공식 문서](https://aws.amazon.com/solutions/implementations/automations-for-aws-firewall-manager/)
- AWS Firewall Manager를 사용하여 조직 내 계정 전체에서 AWS WAF 규칙을 관리한다.
  - AWS Systems Manager Parameter Store 매개변수는 관리할 계정 번호와 OU를 저장하는데 사용된다.
  - 매개변수는 필요에 따라 업데이트되어 계정이나 OU를 추가하거나 제거할 수 있다.
  - EventBridge 규칙은 매개변수에 대한 변경 사항을 식별하고 람다 함수를 호출하여 Firewall Manager 관리 계정의 보안 정책을 업데이트하는데 사용된다.
  - 이 솔루션을 사용하면 운영 오버헤드를 최소화하면서 여러 계정에 걸쳐 AWS WAF 규칙을 쉽게 관리할 수 있다.
- B: 필요에 따라 관리형 AWS WAF 규칙 세트에서 계정이나 OU를 추가하거나 제거할 수 있어야 한다는 요구 사항을 충족하지 않는다.
  - AWS Config 규칙은 규정 준수를 강화하는데 도움이 될 수 있지만, 관리형 규칙 세트만 지원한다.
  - 람다 함수는 규정을 준수하지 않는 리소스를 자동으로 수정하는데 사용할 수 있지만, 복잡하고 관리하기 어려울 수 있다.
  - CloudFormation 스택 세트는 규칙 배포를 자동화하는데 도움이 될 수 있지만, 조직 전체 배포에는 적합하지 않을 수 있다.
- C: 교차 계정 IAM 역할을 수동으로 구성하고 람다 함수에서 역할 가정 호출을 요구하여 운영 오버헤드를 증가시키므로 최선의 접근 방식이 아니다.
  - 람다 함수는 AWS WAF 규칙을 생성하고 업데이트하는데 사용할 수 있지만, 계정 간 액세스 관리가 복잡할 수 있다.
  - AWS STS는 계정 간 액세스를 허용하는데 사용할 수 있지만, 보안 위험을 초래할 수 있다.
  - IAM 역할은 계정 간 액세스를 관리하는데 도움이 될 수 있지만, 설정 및 관리가 복잡할 수 있다.
- D: 여러 계정에 걸쳐 WAF 규칙을 관리하기 위한 중앙 집중식 관리 콘솔을 제공해야 하는 요구 사항을 충족하지 않는다.
  - Control Tower는 조직 전체에서 AWS 리소스를 관리하는데 사용할 수 있지만, AWS WAF 규칙에 대한 특정 지원을 제공하지 않는다.
  - AWS KMS는 키 및 비밀번호를 안전하게 저장하는데 사용할 수 있지만, 계정 번호 및 OU를 저장하는데 적합하지 않다.
  - IAM 사용자는 계정 간 액세스를 관리하는데 도움이 될 수 있지만, 보안 위험을 초래할 수 있다.

---

### 참고한 강의

- [Practice Exam AWS Certified SAP](https://www.udemy.com/course/practice-exam-aws-certified-solutions-architect-professional/learn/quiz/5723044#overview)
- [Examtopics](https://www.examtopics.com/exams/amazon/aws-certified-solutions-architect-professional-sap-c02/view/)
- [DevOps Engineer Professional](https://www.udemy.com/course/aws-certified-devops-engineer-professional-korean)
- [Solutions Architect Professional](https://www.udemy.com/course/aws-solutions-architect-professional)
- [Solutions Architect Associate](https://www.udemy.com/course/best-aws-certified-solutions-architect-associate)
- [SysOps Administrator Associate](https://www.udemy.com/course/ultimate-aws-certified-sysops-administrator-associate)